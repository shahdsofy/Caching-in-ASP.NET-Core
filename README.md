# ğŸš€ Caching in ASP.NET Core 

This README explains **everything related to caching** in ASP.NET Core with **clear concepts, diagrams, and real code examples**.

---

## ğŸ“Œ What is Caching?

Caching is the process of **storing frequently accessed data in fast storage (memory)** to avoid repeated expensive operations such as database calls.

### ğŸ¯ Why Caching?

* Improve performance âš¡
* Reduce database load
* Improve scalability
* Lower response time

---

## ğŸ§  Types of Caching in ASP.NET Core

### 1ï¸âƒ£ In-Memory Cache (IMemoryCache)

* Stored in application RAM
* Fastest caching option
* Per-server (NOT shared)

### 2ï¸âƒ£ Distributed Cache (Redis)

* Shared across multiple servers
* Network-based
* Slightly slower than memory

### 3ï¸âƒ£ Hybrid Cache (Memory + Redis)

* Combines speed + scalability
* Best practice for production

---

## âš¡ IMemoryCache Example

### Program.cs

```csharp
builder.Services.AddMemoryCache();
```

### Usage

```csharp
public class ProductService
{
    private readonly IMemoryCache _cache;

    public ProductService(IMemoryCache cache)
    {
        _cache = cache;
    }

    public async Task<Product> GetProductAsync(int id)
    {
        return await _cache.GetOrCreateAsync($"product_{id}", async entry =>
        {
            entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5);
            return await GetProductFromDatabase(id);
        });
    }
}
```

> If the data is not found in the in-memory cache, the application fetches it from the database and automatically stores it in RAM with an expiration time. Subsequent requests are served directly from memory.

---

## ğŸŒ Distributed Cache (Redis)

### Program.cs

```csharp
builder.Services.AddStackExchangeRedisCache(options =>
{
    options.Configuration = "localhost:6379";
    options.InstanceName = "App:";
});
```

### Usage

```csharp
public async Task<Product> GetProductAsync(int id)
{
    var key = $"product_{id}";
    var cached = await _cache.GetStringAsync(key);

    if (cached != null)
        return JsonSerializer.Deserialize<Product>(cached);

    var product = await GetProductFromDatabase(id);

    await _cache.SetStringAsync(
        key,
        JsonSerializer.Serialize(product),
        new DistributedCacheEntryOptions
        {
            AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(10)
        });

    return product;
}
```

---

## ğŸ”¹ Hybrid Caching 

### Packages to Install

```bash
dotnet add package Microsoft.Extensions.Caching.Hybird

```

### Example Hybrid Code

```csharp
public async Task<Product> GetProductAsync(int id)
{
    string memKey = $"product_{id}";
    string redisKey = $"product_{id}";

    if (_memoryCache.TryGetValue(memKey, out Product product))
        return product;

    var redisData = await _redisCache.GetStringAsync(redisKey);
    if (redisData != null)
    {
        product = JsonSerializer.Deserialize<Product>(redisData);
        _memoryCache.Set(memKey, product, TimeSpan.FromMinutes(1));
        return product;
    }

    product = await GetProductFromDatabase(id);

    _memoryCache.Set(memKey, product, TimeSpan.FromMinutes(1));
    await _redisCache.SetStringAsync(redisKey, JsonSerializer.Serialize(product));

    return product;
}
```


## ğŸ”¹ Two-Level Caching (L1 / L2)

* **L1:** Fast in-memory cache (IMemoryCache)
* **L2:** Distributed cache (Redis, SQL Server, etc.)

```
Request
 â†“
L1: Memory Cache âœ… â†’ Hit â†’ return
 â†“
L2: Redis Cache âŒ â†’ Miss
 â†“
Database
 â†“
Store in L2 & L1
 â†“
Return Data
```



## ğŸ”¹ Tag-Based Cache Invalidation

```csharp
_cache.Set("product_1", product, new MemoryCacheEntryOptions
{
    Tags = new[] { "Products" },
    AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5)
});

// Ù…Ø³Ø­ ÙƒÙ„ Ù…Ù†ØªØ¬Ø§Øª Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
_cache.RemoveByTag("Products");
```



## ğŸ”¹ Configurable Serialization

```csharp
var data = JsonSerializer.Serialize(product);
await _redisCache.SetStringAsync("product_1", data);
```






---

## ğŸ” Cache-Aside Pattern (Most Common)

### Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

Cache-Aside Ù‡Ùˆ Ù†Ù…Ø· ÙŠØªÙ… ÙÙŠÙ‡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„ÙƒØ§Ø´ Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨ ÙÙ‚Ø·. Ø®Ø·ÙˆØ§ØªÙ‡:

1. **Check Cache** â†’ Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø© ØªØ±Ø¬Ø¹ Ù…Ø¨Ø§Ø´Ø±Ø©
2. **Cache Miss** â†’ Load from Database
3. **Store in Cache** â†’ Ø­ÙØ¸ Ø§Ù„Ø¯Ø§ØªØ§ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
4. **Return Data** â†’ Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù„Ù€ Request

### Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø°Ù‡Ù†ÙŠ

```
Request
   â†“
Memory Cache
   â†“
âœ” Hit â†’ return
âŒ Miss
   â†“
Database
   â†“
Cache
   â†“
Return Data
```

### Ù…Ø«Ø§Ù„ ÙƒÙˆØ¯

```csharp
public async Task<Product> GetProductAsync(int id)
{
    if (!_cache.TryGetValue($"product_{id}", out Product product))
    {
        product = await GetProductFromDatabase(id);
        _cache.Set($"product_{id}", product, TimeSpan.FromMinutes(5));
    }
    return product;
}
```

### Ù…Ù…ÙŠØ²Ø§Øª

* Ø¨Ø³ÙŠØ· ÙˆØ³Ù‡Ù„ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚
* ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©

### Ø¹ÙŠÙˆØ¨

* ÙŠØ­ØªØ§Ø¬ Expiration Strategy ÙˆØ§Ø¶Ø­Ø©
* Ø¥Ø°Ø§ Ø¹Ø¯Ø© Ø·Ù„Ø¨Ø§Øª Ø¬Øª ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª â†’ Ù…Ù…ÙƒÙ† ÙŠØ­ØµÙ„ **Cache Stampede**

---

## â±ï¸ Cache Expiration Strategies

### 1ï¸âƒ£ Absolute Expiration

* ÙŠÙ†ØªÙ‡ÙŠ Ø¨Ø¹Ø¯ Ù…Ø¯Ø© Ù…Ø­Ø¯Ø¯Ø© Ù…Ù‡Ù…Ø§ Ø­ØµÙ„

```csharp
_cache.Set("product_1", product, new MemoryCacheEntryOptions
{
    AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5)
});
```

### 2ï¸âƒ£ Sliding Expiration

* ØªØªØ¬Ø¯Ø¯ Ø¹Ù†Ø¯ ÙƒÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù…

```csharp
_cache.Set("user_session_123", sessionData, new MemoryCacheEntryOptions
{
    SlidingExpiration = TimeSpan.FromMinutes(20)
});
```

### Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Absolute Ùˆ Sliding

| Ø§Ù„Ù†Ù‚Ø·Ø©    | Absolute Expiration | Sliding Expiration        |
| --------- | ------------------- | ------------------------- |
| Ù…Ø¯Ø© Ø§Ù„ÙƒØ§Ø´ | Ø«Ø§Ø¨ØªØ©               | ØªØªØ¬Ø¯Ø¯ Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…       |
| Ù…Ù†Ø§Ø³Ø¨ Ù„Ù€  | Ø¨ÙŠØ§Ù†Ø§Øª Ø«Ø§Ø¨ØªØ©        | Ø¬Ù„Ø³Ø§Øª Ø£Ùˆ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØºÙŠØ±Ø©    |
| Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¯Ø© | ÙŠÙ†ØªÙ‡ÙŠ               | ÙŠÙ†ØªÙ‡ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ |

### Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ ÙÙŠ GetOrCreateAsync

```csharp
return await _cache.GetOrCreateAsync("product_1", entry =>
{
    entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5);
    // Ø£Ùˆ
    // entry.SlidingExpiration = TimeSpan.FromMinutes(10);
    return GetProductFromDatabase(1);
});
```

---

## ğŸ”’ Concurrency & Thread Safety

* IMemoryCache is thread-safe
* Distributed cache handles concurrency internally
* Async code must avoid blocking locks

---

## ğŸ’¥ Cache Stampede Protection

* Ù…Ø´ÙƒÙ„Ø©: ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø·Ù„Ø¨Ø§Øª ØªØ¬ÙŠ Ø¹Ù„Ù‰ Key ÙØ§Ø¶ÙŠ â†’ Database overload
* Ø§Ù„Ø­Ù„: Per-Key Async Lock + SemaphoreSlim

```csharp
var semaphore = CacheLocks.Get(cacheKey);
await semaphore.WaitAsync();
try
{
    if (!_memoryCache.TryGetValue(cacheKey, out product))
    {
        product = await GetFromRedisOrDatabase(cacheKey);
        _memoryCache.Set(cacheKey, product, TimeSpan.FromMinutes(5));
    }
}
finally
{
    semaphore.Release();
}
```

---

## ğŸ”‘ SemaphoreSlim & Per-Key Async Locks (Simple Explanation)

> **This section explains these two concepts in very simple words.**

### The Problem

* Cache empty
* 100 requests for the same key (`product_1`)
* Without protection, all hit the database â†’ overload

### SemaphoreSlim

Think of `SemaphoreSlim` as a **door with rules** ğŸšª

```csharp
new SemaphoreSlim(1, 1);
```

* Only **ONE request** enters at a time
* Others wait in line
* Async-safe (works with `async/await`)

### Per-Key Async Lock

* Each cache key has its own lock
* `product_1` has one semaphore
* `product_2` has another semaphore
* Requests for different data run in parallel, requests for same data wait

### Visual Explanation

```
Requests for product_1
   â†“
Semaphore (product_1)
   â†“
ONE request enters
   â†“
Database
   â†“
Cache filled
   â†“
All requests read from cache
```

### Code Example

```csharp
var semaphore = CacheLocks.Get(redisKey);
await semaphore.WaitAsync();
try
{
    // double check cache
    // load from database ONLY ONCE
}
finally
{
    semaphore.Release();
}
```

### Double Check

* Prevents duplicate DB calls if another request filled the cache while waiting


> We prevent cache stampede using per-key async locks implemented with SemaphoreSlim. This ensures only one request fetches data from the database per cache key, while others wait asynchronously until the cache is populated.

---

---
## ğŸ”¹ TryGetValue vs GetOrCreateAsync

### TryGetValue

* Checks if data exists
* Manual handling if cache miss
* Longer code but full control

```csharp
if (_cache.TryGetValue("key", out Product product)) return product;
product = await GetProductFromDatabase(id);
_cache.Set("key", product, TimeSpan.FromMinutes(5));
```

### GetOrCreateAsync

* Checks cache
* If missing â†’ fetch, cache, return automatically
* Shorter code, less control

```csharp
return await _cache.GetOrCreateAsync("key", async entry =>
{
    entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5);
    return await GetProductFromDatabase(id);
});
```

### Comparison Table

| Feature             | TryGetValue | GetOrCreateAsync |
| ------------------- | ----------- | ---------------- |
| Code                | Longer      | Shorter          |
| Storage             | Manual      | Automatic        |
| Control             | High        | Limited          |
| Stampede Protection | Easy        | Hard             |
| Hybrid Cache        | Easy        | Hard             |
| Simple Projects     | âŒ           | âœ”                |
| Complex Projects    | âœ”           | âŒ                |



* TryGetValue: manual, full control, Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ùˆ Hybrid cache
* GetOrCreateAsync: Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒØŒ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø¨Ø³ÙŠØ·

---

## ğŸ”¹ Redis vs IMemoryCache Comparison

| Feature     | IMemoryCache | Redis      |
| ----------- | ------------ | ---------- |
| Speed       | Fastest      | Fast       |
| Shared      | âŒ No         | âœ… Yes      |
| Persistence | âŒ No         | âœ… Optional |
| Scalability | Low          | High       |


---

## ğŸ§© Diagram â€“ Cache Stampede Protection

```
Requests
   â†“
Memory Cache âŒ
   â†“
Redis âŒ
   â†“
Semaphore (per-key)
   â†“
ONE request
   â†“
Database
   â†“
Cache Filled
   â†“
All requests served from cache
```

---
---

## âœ… Best Practices

* Short memory TTL
* Longer Redis TTL
* Invalidate cache on updates
* Avoid global locks
* Monitor cache hit ratio

---

## ğŸ“Œ Conclusion

Caching is a critical performance optimization technique. A well-designed caching strategy improves scalability, reduces load, and ensures system reliability.

---

