# üöÄ Caching in ASP.NET Core ‚Äì Complete Guide

This README explains **everything related to caching** in ASP.NET Core with **clear concepts, diagrams, and real code examples**.
---

## üìå What is Caching?

Caching is the process of **storing frequently accessed data in fast storage (memory)** to avoid repeated expensive operations such as database calls.

### üéØ Why Caching?

* Improve performance ‚ö°
* Reduce database load
* Improve scalability
* Lower response time

---

## üß† Types of Caching in ASP.NET Core

### 1Ô∏è‚É£ In-Memory Cache (IMemoryCache)

* Stored in application RAM
* Fastest caching option
* Per-server (NOT shared)

### 2Ô∏è‚É£ Distributed Cache (Redis)

* Shared across multiple servers
* Network-based
* Slightly slower than memory

### 3Ô∏è‚É£ Hybrid Cache (Memory + Redis)

* Combines speed + scalability
* Best practice for production

---

## ‚ö° IMemoryCache Example

### Program.cs

```csharp
builder.Services.AddMemoryCache();
```

### Usage

```csharp
public class ProductService
{
    private readonly IMemoryCache _cache;

    public ProductService(IMemoryCache cache)
    {
        _cache = cache;
    }

    public async Task<Product> GetProductAsync(int id)
    {
        return await _cache.GetOrCreateAsync($"product_{id}", async entry =>
        {
            entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5);
            return await GetProductFromDatabase(id);
        });
    }
}
```

> If the data is not found in the in-memory cache, the application fetches it from the database and automatically stores it in RAM with an expiration time. Subsequent requests are served directly from memory.

---

## üåê Distributed Cache (Redis)

### Program.cs

```csharp
builder.Services.AddStackExchangeRedisCache(options =>
{
    options.Configuration = "localhost:6379";
    options.InstanceName = "App:";
});
```

### Usage

```csharp
public async Task<Product> GetProductAsync(int id)
{
    var key = $"product_{id}";
    var cached = await _cache.GetStringAsync(key);

    if (cached != null)
        return JsonSerializer.Deserialize<Product>(cached);

    var product = await GetProductFromDatabase(id);

    await _cache.SetStringAsync(
        key,
        JsonSerializer.Serialize(product),
        new DistributedCacheEntryOptions
        {
            AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(10)
        });

    return product;
}
```

---

## üîÅ Cache-Aside Pattern (Most Common)

### Flow

1. Check cache
2. If miss ‚Üí read DB
3. Store result in cache
4. Return response

### Update Handling

```csharp
await UpdateProductInDatabase(product);
_cache.Remove($"product_{product.Id}");
```

---

## ‚è±Ô∏è Cache Expiration Strategies

### 1Ô∏è‚É£ Absolute Expiration 

* ÿßŸÑŸÉÿßÿ¥ ŸäŸÜÿ™ŸáŸä ÿ®ÿπÿØ ŸÖÿØÿ© ŸÖÿ≠ÿØÿØÿ© ŸÖŸáŸÖÿß ÿ≠ÿµŸÑ.
* ÿ®ÿπÿØ ÿßŸÑŸÖÿØÿ© ‚Üí Cache Miss ‚Üí Database

#### ŸÖÿ´ÿßŸÑ ŸÉŸàÿØ

```csharp
_cache.Set(
    "product_1",
    product,
    new MemoryCacheEntryOptions
    {
        AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5)
    });
```

### 2Ô∏è‚É£ Sliding Expiration 

* ŸÖÿØÿ© ÿßŸÑŸÉÿßÿ¥ ÿ™ÿ™ÿ¨ÿØÿØ ÿπŸÜÿØ ŸÉŸÑ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ.
* ÿ•ÿ∞ÿß ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑŸàÿµŸàŸÑ ‚Üí ÿ™ŸÜÿ™ŸáŸä ÿ®ÿπÿØ ÿßŸÑŸÖÿØÿ© ÿßŸÑŸÖÿ≠ÿØÿØÿ©.

#### ŸÖÿ´ÿßŸÑ ŸÉŸàÿØ

```csharp
_cache.Set(
    "user_session_123",
    sessionData,
    new MemoryCacheEntryOptions
    {
        SlidingExpiration = TimeSpan.FromMinutes(20)
    });
```

### ÿßŸÑŸÅÿ±ŸÇ ÿ®ŸäŸÜ Absolute Ÿà Sliding

| ÿßŸÑŸÜŸÇÿ∑ÿ©    | Absolute Expiration | Sliding Expiration           |
| --------- | ------------------- | ---------------------------- |
| ŸÖÿØÿ© ÿßŸÑŸÉÿßÿ¥ | ÿ´ÿßÿ®ÿ™ÿ©               | ÿ™ÿ™ÿ¨ÿØÿØ ÿπŸÜÿØ ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ          |
| ŸÖŸÜÿßÿ≥ÿ® ŸÑŸÄ  | ÿ®ŸäÿßŸÜÿßÿ™ ÿ´ÿßÿ®ÿ™ÿ©        | ÿ¨ŸÑÿ≥ÿßÿ™ ÿ£Ÿà ÿ®ŸäÿßŸÜÿßÿ™ ŸÖÿ™ÿ∫Ÿäÿ±ÿ© ÿ®ŸÉÿ´ÿ±ÿ© |
| ÿ®ÿπÿØ ÿßŸÑŸÖÿØÿ© | ŸäŸÜÿ™ŸáŸä               | ŸäŸÜÿ™ŸáŸä ÿ•ÿ∞ÿß ŸÑŸÖ Ÿäÿ™ŸÖ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸá    |

### ŸÖÿ´ÿßŸÑ ÿπŸÖŸÑŸä ŸÅŸä GetOrCreateAsync

```csharp
return await _cache.GetOrCreateAsync("product_1", entry =>
{
    entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5);
    // ÿ£Ÿà
    // entry.SlidingExpiration = TimeSpan.FromMinutes(10);
    return GetProductFromDatabase(1);
});
```

* AbsoluteExpiration ‚Üí ŸäŸÜÿ™ŸáŸä ÿ®ÿπÿØ ŸàŸÇÿ™ ŸÖÿ≠ÿØÿØ ŸÖŸáŸÖÿß ÿ≠ÿµŸÑ
* SlidingExpiration ‚Üí ŸäŸÜÿ™ŸáŸä ÿ®ÿπÿØ ŸÅÿ™ÿ±ÿ© ŸÖŸÜ ÿ¢ÿÆÿ± ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ

---

## üîí Concurrency & Thread Safety

* IMemoryCache is thread-safe
* Distributed cache handles concurrency internally
* Async code must avoid blocking locks

---

## üí• What is Cache Stampede?

When:

* Cache expires
* Many requests arrive simultaneously
* All hit the database

‚ùå Result: Database overload

---

## üõ°Ô∏è Cache Stampede Protection (Per-Key Async Lock)

### Concept

* Each cache key has its own lock
* Only ONE request fetches from DB
* Others wait asynchronously

---

## üîë SemaphoreSlim & Per-Key Async Locks (Simple Explanation)

> **This section explains these two concepts in very simple wordsÿ≤**

### The Problem

* Cache empty
* 100 requests for the same key (`product_1`)
* Without protection, all hit the database ‚Üí overload

### SemaphoreSlim

Think of `SemaphoreSlim` as a **door with rules** üö™

```csharp
new SemaphoreSlim(1, 1);
```

* Only **ONE request** enters at a time
* Others wait in line
* Async-safe (works with `async/await`)

### Per-Key Async Lock

* Each cache key has its own lock
* `product_1` has one semaphore
* `product_2` has another semaphore
* Requests for different data run in parallel, requests for same data wait

### Visual Explanation

```
Requests for product_1
   ‚Üì
Semaphore (product_1)
   ‚Üì
ONE request enters
   ‚Üì
Database
   ‚Üì
Cache filled
   ‚Üì
All requests read from cache
```

### Code Example

```csharp
var semaphore = CacheLocks.Get(redisKey);
await semaphore.WaitAsync();
try
{
    // double check cache
    // load from database ONLY ONCE
}
finally
{
    semaphore.Release();
}
```

### Double Check

* Prevents duplicate DB calls if another request filled the cache while waiting


> We prevent cache stampede using per-key async locks implemented with SemaphoreSlim. This ensures only one request fetches data from the database per cache key, while others wait asynchronously until the cache is populated.

---

## üîπ TryGetValue vs GetOrCreateAsync

### TryGetValue

* Checks if data exists
* Manual handling if cache miss
* Longer code but full control

```csharp
if (_cache.TryGetValue("key", out Product product)) return product;
product = await GetProductFromDatabase(id);
_cache.Set("key", product, TimeSpan.FromMinutes(5));
```

### GetOrCreateAsync

* Checks cache
* If missing ‚Üí fetch, cache, return automatically
* Shorter code, less control

```csharp
return await _cache.GetOrCreateAsync("key", async entry =>
{
    entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5);
    return await GetProductFromDatabase(id);
});
```

### Comparison Table

| Feature             | TryGetValue | GetOrCreateAsync |
| ------------------- | ----------- | ---------------- |
| Code                | Longer      | Shorter          |
| Storage             | Manual      | Automatic        |
| Control             | High        | Limited          |
| Stampede Protection | Easy        | Hard             |
| Hybrid Cache        | Easy        | Hard             |
| Simple Projects     | ‚ùå           | ‚úî                |
| Complex Projects    | ‚úî           | ‚ùå                |

### Summary

* **Use TryGetValue**: large projects, hybrid cache, Redis, high concurrency, cache stampede protection
* **Use GetOrCreateAsync**: simple projects, single server, small apps

---

## üß© Diagram ‚Äì Cache Stampede Protection

```
Requests
   ‚Üì
Memory Cache ‚ùå
   ‚Üì
Redis ‚ùå
   ‚Üì
Semaphore (per-key)
   ‚Üì
ONE request
   ‚Üì
Database
   ‚Üì
Cache Filled
   ‚Üì
All requests served from cache
```

---

## üî• Redis vs IMemoryCache Comparison

| Feature     | IMemoryCache | Redis      |
| ----------- | ------------ | ---------- |
| Speed       | Fastest      | Fast       |
| Shared      | ‚ùå No         | ‚úÖ Yes      |
| Persistence | ‚ùå No         | ‚úÖ Optional |
| Scalability | Low          | High       |

---

## üß† Hybrid Cache Strategy (Best Practice)

```
Request
 ‚Üì
Memory Cache
 ‚Üì
Redis
 ‚Üì
Database
```

‚úî Fast
‚úî Scalable
‚úî Production-ready

---


> We use hybrid caching with IMemoryCache and Redis, apply cache-aside pattern, handle expiration properly, and prevent cache stampede using per-key async locks with SemaphoreSlim to protect the database under high concurrency.

---

## ‚úÖ Best Practices

* Short memory TTL
* Longer Redis TTL
* Invalidate cache on updates
* Avoid global locks
* Monitor cache hit ratio

---

## üìå Conclusion

Caching is a critical performance optimization technique. A well-designed caching strategy improves scalability, reduces load, and ensures system reliability.

---

